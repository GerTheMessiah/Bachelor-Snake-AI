% Encoding: UTF-8

@Article{UAV,
  author  = {Chunxue, Wu and Ju, Bobo and Wu, Yan and Lin, Xiao and Xiong, Naixue and Xu, Guangquan and Li, Hongyan and Liang, Xuefeng},
  journal = {IEEE Access},
  title   = {{UAV Autonomous Target Search Based on Deep Reinforcement Learning in Complex Disaster Scene}},
  year    = {2019},
  month   = {08},
  pages   = {1-1},
  volume  = {PP},
  doi     = {10.1109/ACCESS.2019.2933002},
  url     = {https://ieeexplore.ieee.org/abstract/document/8787847},
}

@InProceedings{Autonomous_Agents_in_Snake_Game_via_DRL,
  author    = {Wei, Zhepei and Wang, Di and Zhang, Ming and Tan, Ah-Hwee and Miao, Chunyan and Zhou, You},
  booktitle = {2018 IEEE International Conference on Agents (ICA)},
  title     = {Autonomous Agents in Snake Game via Deep Reinforcement Learning},
  year      = {2018},
  pages     = {20-25},
  doi       = {10.1109/AGENTS.2018.8460004},
}

@Misc{Finnson1342302,
  author      = {Finnson, Anton and Moln{\"o}, Victor},
  title       = {Djupinl{\"a}rning p{\aa} Snake},
  year        = {2019},
  abstract    = {Algoritmer baserade på reinforcement learning har framgångsrikt tillämpats på många olika maskininlärningsproblem. I denna rapport presenterar vi hur vi implementerar varianter på deep Q-learning-algoritmer på det klassiska datorspelet Snake. Vi ämnar undersöka hur en sådan algoritm ska konfigureras för att lära sig spela Snake så bra som möjligt. För att göra detta studerar vi hur inlärningen beror på ett urval av parametrar, genom att variera dessa en och en och studera resultaten. Utifrån detta lyckas vi konstruera en algoritm som lär sig spela spelet så pass bra att den som högst får 66 poäng, vilket motsvarar att täcka 46 % av spelplanen, efter drygt fem timmars träning. Vidare så finner vi att den tränade algoritmen utan större svårigheter hanterar att hinder introduceras i spelet.  },
  institution = {KTH, School of Engineering Sciences (SCI)},
  number      = {2019:249},
  school      = {KTH, School of Engineering Sciences (SCI)},
  series      = {TRITA-SCI-GRU},
}

@Article{PPO,
  author        = {John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
  journal       = {CoRR},
  title         = {Proximal Policy Optimization Algorithms},
  year          = {2017},
  volume        = {abs/1707.06347},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/SchulmanWDRK17.bib},
  eprint        = {1707.06347},
  timestamp     = {Mon, 13 Aug 2018 16:47:34 +0200},
  url           = {http://arxiv.org/abs/1707.06347},
}

@Article{DBLP:journals/corr/MnihKSGAWR13,
  author        = {Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin A. Riedmiller},
  journal       = {CoRR},
  title         = {Playing Atari with Deep Reinforcement Learning},
  year          = {2013},
  volume        = {abs/1312.5602},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/MnihKSGAWR13.bib},
  eprint        = {1312.5602},
  timestamp     = {Mon, 13 Aug 2018 16:47:42 +0200},
  url           = {http://arxiv.org/abs/1312.5602},
}

@Misc{Exploration_of_Reinforcement_Learning_to_SNAKE,
  author  = {Bowei Ma, Meng Tang, Jun Zhang},
  title   = {{Exploration of Reinforcement Learning to SNAKE}},
  year    = {2016},
  journal = {cs229},
  url     = {http://cs229.stanford.edu/proj2016spr/report/060.pdf},
}

@Article{SAC,
  author        = {Tuomas Haarnoja and Aurick Zhou and Pieter Abbeel and Sergey Levine},
  journal       = {CoRR},
  title         = {{Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor}},
  year          = {2018},
  volume        = {abs/1801.01290},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1801-01290.bib},
  eprint        = {1801.01290},
  timestamp     = {Mon, 13 Aug 2018 16:48:10 +0200},
  url           = {http://arxiv.org/abs/1801.01290},
}

@Article{DQN,
  author      = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  journal     = {Nature},
  title       = {Human-level control through deep reinforcement learning},
  year        = {2015},
  issn        = {00280836},
  month       = feb,
  number      = {7540},
  pages       = {529--533},
  volume      = {518},
  added-at    = {2015-08-26T14:46:40.000+0200},
  biburl      = {https://www.bibsonomy.org/bibtex/2fb15f4471c81dc2b9edf2304cb2f7083/hotho},
  description = {Human-level control through deep reinforcement learning - nature14236.pdf},
  interhash   = {eac59980357d99db87b341b61ef6645f},
  intrahash   = {fb15f4471c81dc2b9edf2304cb2f7083},
  keywords    = {deep learning toread},
  publisher   = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  timestamp   = {2015-08-26T14:46:40.000+0200},
  url         = {http://dx.doi.org/10.1038/nature14236},
}

@Book{DRL_Lapan,
  author    = {Lapan, Maxim},
  publisher = {MITP Verlags GmbH},
  title     = {{Deep Reinforcement Learning - Das umfassende Praxis-Handbuch}},
  year      = {2020},
  isbn      = {3747500366},
  date      = {2020-07-01},
  ean       = {9783747500361},
  pagetotal = {762},
  url       = {https://www.ebook.de/de/product/37826629/maxim_lapan_deep_reinforcement_learning.html},
}

@Book{Sutton1998,
  author    = {Sutton, Richard S. and Barto, Andrew G.},
  publisher = {The MIT Press},
  title     = {{Reinforcement Learning: An Introduction}},
  year      = {2018},
  edition   = {Second},
  added-at  = {2019-07-13T10:11:53.000+0200},
  biburl    = {https://www.bibsonomy.org/bibtex/2f46601cf8b13d39d1378af0d79438b12/lanteunis},
  interhash = {ac6b144aaec1819919a2fba9f705c852},
  intrahash = {f46601cf8b13d39d1378af0d79438b12},
  timestamp = {2019-07-13T10:11:53.000+0200},
  url       = {http://incompleteideas.net/book/bookdraft2018jan1.pdf},
}

@Article{asynchronous_methods_for_deep_rl,
  author        = {Volodymyr Mnih and Adri{\`{a}} Puigdom{\`{e}}nech Badia and Mehdi Mirza and Alex Graves and Timothy P. Lillicrap and Tim Harley and David Silver and Koray Kavukcuoglu},
  journal       = {CoRR},
  title         = {{Asynchronous Methods for Deep Reinforcement Learning}},
  year          = {2016},
  volume        = {abs/1602.01783},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/MnihBMGLHSK16.bib},
  eprint        = {1602.01783},
  timestamp     = {Mon, 13 Aug 2018 16:47:40 +0200},
  url           = {http://arxiv.org/abs/1602.01783},
}

@Article{TRPO,
  author        = {John Schulman and Sergey Levine and Philipp Moritz and Michael I. Jordan and Pieter Abbeel},
  journal       = {CoRR},
  title         = {{Trust Region Policy Optimization}},
  year          = {2015},
  volume        = {abs/1502.05477},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/SchulmanLMJA15.bib},
  eprint        = {1502.05477},
  timestamp     = {Mon, 13 Aug 2018 16:48:08 +0200},
  url           = {http://arxiv.org/abs/1502.05477},
}

@Article{DBLP:journals/corr/abs-1909-07528,
  author        = {Bowen Baker and Ingmar Kanitscheider and Todor M. Markov and Yi Wu and Glenn Powell and Bob McGrew and Igor Mordatch},
  journal       = {CoRR},
  title         = {Emergent Tool Use From Multi-Agent Autocurricula},
  year          = {2019},
  volume        = {abs/1909.07528},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1909-07528.bib},
  eprint        = {1909.07528},
  timestamp     = {Wed, 29 Jul 2020 10:46:01 +0200},
  url           = {http://arxiv.org/abs/1909.07528},
}

@Book{DL,
  author    = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  publisher = {MITP Verlags GmbH},
  title     = {Deep Learning. Das umfassende Handbuch},
  year      = {2018},
  isbn      = {3958457002},
  date      = {2018-11-01},
  ean       = {9783958457003},
  url       = {https://www.ebook.de/de/product/31366940/ian_goodfellow_yoshua_bengio_aaron_courville_deep_learning_das_umfassende_handbuch.html},
}

@Misc{Deep_RL_Bootcamp,
  author       = {John Schulman},
  howpublished = {\url{https://www.youtube.com/watch?v=xvRrgxcpaHY}},
  month        = oct,
  title        = {Deep RL Bootcamp Lecture 5: Natural Policy Gradients, TRPO, PPO},
  year         = {2017},
  day          = {06},
}

@Comment{jabref-meta: databaseType:bibtex;}
