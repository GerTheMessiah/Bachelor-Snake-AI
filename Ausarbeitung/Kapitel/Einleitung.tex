\chapter{Einleitung}\label{sec:beispiel}
Das Maschine Learning ist weltweit auf dem Vormarsch und große Unternehmen investieren riesige Beträge, um mit KI basierten Lösungen größere Effizienz zu erreichen. Auch der Bereich des Reinforcement Learning gerät dabei immer mehr in das Blickfeld von der Weltöffentlichkeit. Besonders im Gaming Bereich hat das Reinforcement Learning schon beeindruckende Resultate erbringen können, wie z.B. die KI AlphaGO, welche den amtierenden Weltmeister Lee Sedol im Spiel GO besiegt hat \cite{UAV}. In Anlehnung an die vielen neuen Reinforcement Learning Möglichkeiten, die in der letzten Zeit entwickelt wurden und vor dem Hintergrund der immer größer werdenden Beliebtheit von KI basierten Lösungsstrategien, soll es in dieser Bachelorarbeit darum gehen, einzelnen Reinforcement Learning Agenten, mittels statistischer Methoden, genauer zu untersuchen and den optimalen Agenten für ein entsprechendes Problem zu bestimmen.

\section{Motivation}
In den letzen Jahren erregte das Reinforcement Learning eine immer größere Aufmerksamkeit. Siege über die amtierenden Weltmeister in den Spielen GO oder Schach führten zu einer zumehmenden Beliebtheit des RL. Neue Verfahren, wie z.B. der Deep Q-Network Algorithmus auf dem Jahr 2015 \cite{DQN}, der Proximal Policy Optimization (PPO) aus dem Jahr 2017 \cite{PPO} oder der Soft Actor Critic (SAC) aus dem Jahr 2018 \cite{SAC}, haben ihr Übriges getan, um das RL auch in anderen Bereichen weiter anzusiedeln, wie z.B. der Finanzwelt, im autonomen Fahren, in der Steuerung von Robotern, in der Navigation im Web oder als Chatbot \cite{DRL}.\\
Durch die jedoch große Menge an RL-Verfahren gerät man zunehmend in die problematische Situaion, sich für einen diskreten RL Ansatz zu entscheiden. Weiter erschwert wird dieser Auswahlprozess noch durch die Tatsache, dass die einzelnen Agenten jeweils untereinander große Unterschiede aufweisen. Auch existieren häufig mehrere Ausprägungen eines RL-Verfahrens, wie z.B. der Deep Q-Network Algorithmus (DQN) und der Double Deep Q-Network Algorithmus (DDQN). Die Wahl des passenden Agenten kann großen Einfluss auf die Performance haben \cite{SnakeRL2016}, deshalb soll in dieser Ausarbeitung eine Methodik, welche auf einem Vergleich berut, entwickelt werden, die den passenden Agenten für eine entsprechendes Problem bestimmt.\\
Aufgrund der Tatsache, dass die Durchführung der erwähnten Methodik an mehrere Umgebungen den Rahmen sprengen würde, wurde sich für ein spezifische Umgebung zum Testen entschieden. Die Wahl fiel dabei auf das Computerspiel Snake.
Damit ergib sich die folgende Forschungsfrage:\\
Wie kann an einem Beispiel des Spiels Snake für eine nicht-triviale geringdimensionale Umgebung ein möglichst optimaler RL Agent ermittelt werden?\\
\\Basierend auf der Forschungsfrage ergibt sich ein Mehrwert für die Wissenschaft. Durch die Abnahme des Entscheidungsfindungsprozesses müssen Forscherinnen und Forscher wie auch Anwenderinnen und Anwender von RL-Verfahren nicht mehr unreflektiert irgendeinen RL Agenten auswählen, sondern können auf Grundlage der Methodik und der daraus hervorgehenden Daten den passenden Agenten bestimmen.\\
\\Mit der Wahl des Spiels Snake ist zusätzlich zu dem oben erwähnten Mehrwert noch ein weiterer in Erscheinung getreten. So interpretieren neue Forschungsanätze das Spiel Snake als ein dynamisches Pathfinding Problem. Mit dieser Art von Problemen sind auch unbemannte Drohne (UAV Drohnen) konfrontiert, welche beispielsweise Menschen in komplexen Katastrophensituationen, wie z.B. auf explodierten Rohölbohrplattformen oder Raffenerien, finden und retten sollen. Auch kann das Liefen von wichtigen Gütern, beispielsweise medizinischer Natur, in solche Gebiete kann durch die Forschung am Spiel Snake möglich gemacht werden \cite{UAV}.
Somit kann der RL-Vergleich am Spiel Snake möglicherweise helfen, Menschen zu retten.

