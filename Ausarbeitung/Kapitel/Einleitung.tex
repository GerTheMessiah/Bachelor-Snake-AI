\chapter{Einleitung}\label{chap:Einleitung}
In dieser Ausarbeitung wird das Generische Maskulinum verwendet. Dieses soll niemanden beleidigen und oder diskriminieren.\\
\\Das Machine Learning ist weltweit auf dem Vormarsch und große Unternehmen investieren riesige Beträge, um mit KI basierten Lösungen größere Effizienz zu erreichen. Auch der Bereich des Reinforcement Learning gerät dabei immer mehr in das Blickfeld der Weltöffentlichkeit. Besonders im Gaming Bereich hat das Reinforcement Learning schon beeindruckende Resultate erbringen können, wie z.B. die KI AlphaGO, welche den amtierenden Weltmeister Lee Sedol im Spiel GO besiegt hat \citep{UAV}. In Anlehnung an die vielen neuen Reinforcement Learning Möglichkeiten, welche in der letzten Zeit entwickelt wurden und vor dem Hintergrund der immer größer werdenden Beliebtheit von KI basierten Lösungsstrategien, soll es in dieser Bachelorarbeit darum gehen, einzelnen Reinforcement Learning Agenten, mittels statistischer Methoden, genauer zu untersuchen und den optimalen Agenten für ein entsprechendes Problem zu bestimmen.

\section{Motivation} \label{sec:Einleitung_Motivation}
In den letzten Jahren erregte das Reinforcement Learning eine immer größer werdende Aufmerksamkeit. Siege über die amtierenden Weltmeister in den Spielen GO oder Schach führten zu einer zunehmenden Beliebtheit des RL. Weiterhin wurde dieser Effekt durch neue Verfahren, wie z.B. der Deep Q-Network Algorithmus auf dem Jahr 2015 \citep{DQN}, der Proximal Policy Optimization (PPO) aus dem Jahr 2017 \citep{PPO} oder der Soft Actor Critic (SAC) aus dem Jahr 2018 \citep{SAC}, verstärkt. Heutzutage findet das RL auch in anderen Bereichen Anwendung, wie z.B. in der Finanzwelt, im autonomen Fahren usw.\\
Durch die jedoch große Menge an RL Verfahren gerät man zunehmend in die problematische Situation, sich für einen diskreten RL Ansatz zu entscheiden. Weiter wird dieser Auswahlprozess erschwert durch die Tatsache, dass die einzelnen RL Agenten jeweils untereinander große Unterschiede aufweisen. Auch existieren gelegentlich mehrere Ausprägungen eines RL Algorithmus, so wird z.B. der Deep Q-Network Algorithmus (DQN) durch den Double Deep Q-Network Algorithmus (DDQN) erweitert. Die Wahl des Agenten kann großen Einfluss auf die Performance und andere Bewertungskriterien haben \citep{Exploration_of_Reinforcement_Learning_to_SNAKE}, deshalb soll in dieser Ausarbeitung ein Vorgehen entwickelt werden, welches, basierend auf einem Vergleich, den optimalen Agenten für ein entsprechendes Problem bestimmt.\\
\\Eine potenzielle Umgebung, in welcher Agenten getestet und verglichen werden können, ist das Spiel Snake.
Mit der Wahl dieses Spiels ist zusätzlich noch ein weiterer Mehrwert in Erscheinung getreten.\\ 
So interpretieren neue Forschungsansätze das Spiel Snake als ein dynamisches Pathfinding Problem. Mit dieser Art von Problemen sind auch unbemannte Drohne (UAV Drohnen) konfrontiert, welche beispielsweise Menschen in komplexen Katastrophensituationen, wie z.B. auf zerstörten Rohölbohrplattformen, finden und unterstützen sollen. 
Auch das Liefen von wichtigen Gütern in solche Gebiete zählt zu den Aufgaben dieser Drohnen.
Mit der Forschung am Spiel Snake ist es möglich, zumindest einen kleinen Beitrag zu diesem Forschungsfeld zu leisten. \citep{UAV}

\section{Zielsetzung} \label{sec:Einleitung_Forschungsfrage}
Basierend auf der Motivation ergibt sich folgende Fragestellung für diese Ausarbeitung:\\
\textbf{Wie kann am Beispiel des Spiels Snake für eine nicht triviale gering dimensionale Umgebung ein möglichst optimaler RL Agent ermittelt werden?}\\
Diese Fragestellung zielt darauf ab, für die Umgebung Snake einen möglichst optimalen Agenten zu bestimmen, welcher spezifische Anforderungen erfüllen soll.\\
Durch Abnahme des Entscheidungsfindungsprozesses müssen Forscher und Anwender von RL Verfahren nicht mehr unreflektiert RL Agenten auswählen, sondern können auf Grundlage der Methodik und der daraus hervorgehenden Daten den passenden Agenten bestimmen.

